{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z59UBmna3udY",
        "outputId": "ed388f43-2025-4d66-95a8-3bb3bd7545de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import optuna"
      ],
      "metadata": {
        "id": "coE5fieM3t2H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MaWhsPRe3qxI"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_conv_layers, n_filters, n_fc_layers, n_neurons, dropout_rate):\n",
        "        super(Net, self).__init__()\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        image_size = 32\n",
        "\n",
        "        # Add convolutional layers\n",
        "        for i in range(n_conv_layers):\n",
        "            layers.append(nn.Conv2d(in_channels, n_filters, kernel_size=3, padding=1))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.MaxPool2d(2, 2))\n",
        "            in_channels = n_filters\n",
        "\n",
        "        # Calculate the final image size after convolution and pooling\n",
        "        image_size = image_size // (2 ** n_conv_layers)\n",
        "\n",
        "        # Add fully connected layers\n",
        "        layers.append(nn.Flatten())\n",
        "        in_features = n_filters * image_size * image_size  # Update in_features for the first linear layer\n",
        "        for i in range(n_fc_layers):\n",
        "            layers.append(nn.Linear(in_features, n_neurons))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(p=dropout_rate))\n",
        "            in_features = n_neurons  # Update in_features for the next layer\n",
        "\n",
        "        layers.append(nn.Linear(in_features, 100))  # 100 output classes for CIFAR-100\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Function to get the CIFAR-100 data loaders\n",
        "def get_data_loaders(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate(model, optimizer, criterion, trainloader, testloader, device, trial, epochs=10):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        ## Calculate accuracy for training phase\n",
        "        train_accuracy = train_correct / train_total\n",
        "        ## NORMAL running_loss over batches\n",
        "        running_loss /= len(trainloader)\n",
        "\n",
        "        model.eval()\n",
        "        test_total = 0\n",
        "        test_correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data in testloader:\n",
        "                images, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        ## Calculate accuracy for test phase\n",
        "        test_accuracy = test_correct / test_total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.3f}, TrAccuracy: {100 * train_accuracy:.2f}%, TeAccuracy: {100 * test_accuracy:.2f}\")\n",
        "\n",
        "        # Report intermediate result to Optuna for pruning\n",
        "        trial.report(test_accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate result\n",
        "        if test_accuracy < 0.06:\n",
        "            print(\"Trial pruned due to low accuracy.\")\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    return 1 - test_accuracy\n",
        "\n",
        "\n",
        "# Define the optimization objective\n",
        "def objective(trial):\n",
        "    # Set up the hyperparameters to optimize\n",
        "    n_conv_layers = trial.suggest_int('n_conv_layers', 1, 4)\n",
        "    n_filters = trial.suggest_int('n_filters', 16, 64)\n",
        "    n_fc_layers = trial.suggest_int('n_fc_layers', 1, 3)\n",
        "    n_neurons = trial.suggest_int('n_neurons', 16, 64)\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 1e-2)\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop', 'SGD'])\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Get data loaders\n",
        "    trainloader, testloader = get_data_loaders(batch_size=128)\n",
        "\n",
        "    # Create the model\n",
        "    model = Net(n_conv_layers, n_filters, n_fc_layers, n_neurons, dropout_rate)\n",
        "\n",
        "    # Set up the optimizer and loss criterion\n",
        "    if optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_name == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "    else:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    error_rate = train_and_evaluate(model, optimizer, criterion, trainloader, testloader, device, trial)\n",
        "\n",
        "    return error_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Optuna study\n",
        "study = optuna.create_study(direction='minimize')\n",
        "\n",
        "try:\n",
        "    study.optimize(objective, timeout=3600, n_jobs=1)\n",
        "except optuna.exceptions.TrialPruned as e:\n",
        "    print(\"Trial was pruned.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUQHKMOC3-Ns",
        "outputId": "bc1b39c9-7e40-4369-d2ce-551ad766c5ae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:00:13,476] A new study created in memory with name: no-name-ead9a5fb-e564-442e-bd3f-e6c375b47347\n",
            "<ipython-input-27-ae6992357a73>:108: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
            "<ipython-input-27-ae6992357a73>:109: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:02:01,983] Trial 0 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 4.609, TrAccuracy: 0.89%, TeAccuracy: 0.69\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:02:58,526] Trial 1 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 4.609, TrAccuracy: 0.98%, TeAccuracy: 1.21\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10, Loss: 4.125, TrAccuracy: 5.84%, TeAccuracy: 9.56\n",
            "Epoch 2/10, Loss: 3.736, TrAccuracy: 11.62%, TeAccuracy: 13.72\n",
            "Epoch 3/10, Loss: 3.533, TrAccuracy: 15.12%, TeAccuracy: 16.94\n",
            "Epoch 4/10, Loss: 3.357, TrAccuracy: 18.34%, TeAccuracy: 20.62\n",
            "Epoch 5/10, Loss: 3.219, TrAccuracy: 20.95%, TeAccuracy: 22.59\n",
            "Epoch 6/10, Loss: 3.111, TrAccuracy: 23.09%, TeAccuracy: 23.77\n",
            "Epoch 7/10, Loss: 3.027, TrAccuracy: 24.72%, TeAccuracy: 23.13\n",
            "Epoch 8/10, Loss: 2.958, TrAccuracy: 25.94%, TeAccuracy: 25.45\n",
            "Epoch 9/10, Loss: 2.889, TrAccuracy: 27.40%, TeAccuracy: 26.90\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:15:34,692] Trial 2 finished with value: 0.7294 and parameters: {'n_conv_layers': 4, 'n_filters': 29, 'n_fc_layers': 1, 'n_neurons': 38, 'dropout_rate': 0.023047056097617258, 'learning_rate': 0.0013114050805727497, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.7294.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Loss: 2.826, TrAccuracy: 28.51%, TeAccuracy: 27.06\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:16:54,842] Trial 3 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 4.612, TrAccuracy: 0.97%, TeAccuracy: 1.00\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:17:35,762] Trial 4 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 4.596, TrAccuracy: 1.48%, TeAccuracy: 2.73\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:18:33,949] Trial 5 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 4.383, TrAccuracy: 2.54%, TeAccuracy: 3.99\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10, Loss: 4.284, TrAccuracy: 3.75%, TeAccuracy: 7.59\n",
            "Epoch 2/10, Loss: 3.870, TrAccuracy: 9.03%, TeAccuracy: 14.24\n",
            "Epoch 3/10, Loss: 3.589, TrAccuracy: 14.07%, TeAccuracy: 19.33\n",
            "Epoch 4/10, Loss: 3.386, TrAccuracy: 17.46%, TeAccuracy: 20.85\n",
            "Epoch 5/10, Loss: 3.244, TrAccuracy: 20.09%, TeAccuracy: 22.97\n",
            "Epoch 6/10, Loss: 3.124, TrAccuracy: 22.32%, TeAccuracy: 25.56\n",
            "Epoch 7/10, Loss: 3.022, TrAccuracy: 23.83%, TeAccuracy: 27.49\n",
            "Epoch 8/10, Loss: 2.942, TrAccuracy: 25.56%, TeAccuracy: 28.41\n",
            "Epoch 9/10, Loss: 2.864, TrAccuracy: 27.25%, TeAccuracy: 29.09\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:45:00,854] Trial 6 finished with value: 0.7025 and parameters: {'n_conv_layers': 4, 'n_filters': 51, 'n_fc_layers': 1, 'n_neurons': 33, 'dropout_rate': 0.1606175987855336, 'learning_rate': 0.0017532461052205608, 'optimizer': 'RMSprop'}. Best is trial 6 with value: 0.7025.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Loss: 2.795, TrAccuracy: 28.33%, TeAccuracy: 29.75\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:47:13,592] Trial 7 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 4.603, TrAccuracy: 1.28%, TeAccuracy: 1.75\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:49:19,542] Trial 8 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 4.612, TrAccuracy: 1.02%, TeAccuracy: 1.00\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:51:14,554] Trial 9 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 5.526, TrAccuracy: 0.86%, TeAccuracy: 1.00\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:54:03,431] Trial 10 pruned. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 4.575, TrAccuracy: 1.78%, TeAccuracy: 3.43\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 12:55:16,645] Trial 11 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 4.395, TrAccuracy: 2.76%, TeAccuracy: 5.41\n",
            "Trial pruned due to low accuracy.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10, Loss: 4.127, TrAccuracy: 6.50%, TeAccuracy: 13.07\n",
            "Epoch 2/10, Loss: 3.619, TrAccuracy: 13.98%, TeAccuracy: 18.94\n",
            "Epoch 3/10, Loss: 3.378, TrAccuracy: 18.26%, TeAccuracy: 23.52\n",
            "Epoch 4/10, Loss: 3.208, TrAccuracy: 21.31%, TeAccuracy: 24.90\n",
            "Epoch 5/10, Loss: 3.074, TrAccuracy: 23.66%, TeAccuracy: 25.86\n",
            "Epoch 6/10, Loss: 2.963, TrAccuracy: 25.60%, TeAccuracy: 30.01\n",
            "Epoch 7/10, Loss: 2.870, TrAccuracy: 27.47%, TeAccuracy: 30.98\n",
            "Epoch 8/10, Loss: 2.794, TrAccuracy: 29.17%, TeAccuracy: 33.15\n",
            "Epoch 9/10, Loss: 2.726, TrAccuracy: 30.34%, TeAccuracy: 32.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-07-01 13:18:08,410] Trial 12 finished with value: 0.6644 and parameters: {'n_conv_layers': 3, 'n_filters': 49, 'n_fc_layers': 1, 'n_neurons': 49, 'dropout_rate': 0.17971506180255348, 'learning_rate': 0.0017326535267501914, 'optimizer': 'RMSprop'}. Best is trial 12 with value: 0.6644.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 2.678, TrAccuracy: 31.02%, TeAccuracy: 33.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters and error rate\n",
        "best_params = study.best_params\n",
        "best_error = study.best_value\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Error Rate:\", best_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpUu8mJJ6sys",
        "outputId": "d2571255-f9fd-43f4-fb0f-0b17b4dc45a5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_conv_layers': 3, 'n_filters': 49, 'n_fc_layers': 1, 'n_neurons': 49, 'dropout_rate': 0.17971506180255348, 'learning_rate': 0.0017326535267501914, 'optimizer': 'RMSprop'}\n",
            "Best Error Rate: 0.6644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPIViBDLnE6d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}